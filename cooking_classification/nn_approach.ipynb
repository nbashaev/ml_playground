{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport gc\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.optimizers import Adam",
      "execution_count": 78,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_raw_data = pd.read_json('../input/train.json').set_index('id')\ntest_raw_data = pd.read_json('../input/test.json').set_index('id')\n\ndf = pd.concat([train_raw_data.drop(\"cuisine\", axis=1), test_raw_data], axis=0)\ny = train_raw_data['cuisine']\n\ntraindex = train_raw_data.index\ntestdex = test_raw_data.index\ndf_index = df.index\n\ndel train_raw_data, test_raw_data\ngc.collect()\n\n# X preprocess\n\ndef unify(word_list):\n    word_list = ' '.join(word_list).lower()\n    word_list = re.sub('[^a-z]', ' ', word_list)\n    word_list = re.sub(' +', ' ', word_list).strip()\n    return word_list\n\ndf['ingredients'] = df['ingredients'].apply(unify)\ningredients = pd.Series(' '.join(df['ingredients'].tolist()).split(' '))\nv_counts = ingredients.value_counts()\n\nvect = CountVectorizer(tokenizer=lambda x: x.split(' '))\ndummies = vect.fit_transform(df['ingredients'])\nnew_df = pd.DataFrame(dummies.todense(), columns=vect.get_feature_names())\nnew_df.index = df_index\n\ncolumns_list = v_counts[v_counts <= 2].index\nnew_df = new_df.drop(columns=columns_list)\n\nX = new_df.loc[traindex,:]\nX_test = new_df.loc[testdex,:]\n\nvalid_rows = (X.sum(axis=1) >= 2)\nX = X[valid_rows]; y = y[valid_rows]\n\ndel df, new_df, dummies\ngc.collect()\n\n# y preprocess\n\ny_lbr = LabelBinarizer()\ny = y_lbr.fit_transform(y)\n\ny_classes = y_lbr.classes_\ny_classes_transformed = y_lbr.transform(y_classes)\n\n# dataset split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n\ndel X, y\ngc.collect()\n\nprint(X_train.shape)\nprint(y_train.shape)",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(35791, 2321)\n(35791, 20)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cb735afedf42714ead220d4e3c8d0d06e89bd685"
      },
      "cell_type": "code",
      "source": "def get_model():\n    i = Input(shape=X_train.shape[1:])\n    x = Dropout(0.4)(i)\n    x = Dense(600)(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n    o = Dense(y_train.shape[1], activation='linear')(x)\n    o = Dense(y_train.shape[1], activation='softmax')(o)\n    \n    return Model(inputs=[i,], outputs=[o,])\n\nmodel = get_model()\nmodel.summary()",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_18 (InputLayer)        (None, 2321)              0         \n_________________________________________________________________\ndropout_35 (Dropout)         (None, 2321)              0         \n_________________________________________________________________\ndense_43 (Dense)             (None, 600)               1393200   \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 600)               2400      \n_________________________________________________________________\nactivation_18 (Activation)   (None, 600)               0         \n_________________________________________________________________\ndropout_36 (Dropout)         (None, 600)               0         \n_________________________________________________________________\ndense_44 (Dense)             (None, 20)                12020     \n_________________________________________________________________\ndense_45 (Dense)             (None, 20)                420       \n=================================================================\nTotal params: 1,408,040\nTrainable params: 1,406,840\nNon-trainable params: 1,200\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c4517038f56722effab41564974d9297003fb04"
      },
      "cell_type": "code",
      "source": "lr = 0.005\nepochs = 100\n\nmodel.compile(loss='categorical_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=33, verbose=1),\n    ModelCheckpoint('best_loss.model', monitor='val_loss', save_best_only=True, verbose=0),\n    ModelCheckpoint('best_acc.model', monitor='val_acc', save_best_only=True, verbose=0),\n    ReduceLROnPlateau(factor=0.3, patience=7, min_lr=0.00001, verbose=0)\n]\n\nhistory = model.fit(\n    x=[X_train,],\n    y=[y_train]*1,\n    validation_data=[[X_val,], [y_val]*1],\n    callbacks=callbacks,\n    epochs=epochs,\n    batch_size=256,\n    shuffle=True,\n    verbose=2\n)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf9492d3b388a5f68b6ae4aa6646413d746cb5a3"
      },
      "cell_type": "code",
      "source": "for tmp in ['loss', 'acc']:\n    best_model = load_model('best_{}.model'.format(tmp))\n    \n    print('best {} model'.format(tmp))\n    print(best_model.evaluate([X_val,], [y_val]*1, verbose=0), end='\\n\\n')\n    \n    y_test = best_model.predict(X_test, verbose=0)\n    y_test = y_lbr.inverse_transform(y_test)\n    submission_df = pd.Series(y_test, index=testdex).rename('cuisine')\n    submission_df.to_csv(\"nn_best_{}.csv\".format(tmp), index=True, header=True)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}